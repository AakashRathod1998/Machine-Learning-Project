{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, f1_score, confusion_matrix\n",
    "from sklearn.impute import SimpleImputer \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Dataset\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "raw_df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
    "X, y = iris.data, iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature scaling with StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)  \n",
       "count        150.000000  \n",
       "mean           1.199333  \n",
       "std            0.762238  \n",
       "min            0.100000  \n",
       "25%            0.300000  \n",
       "50%            1.300000  \n",
       "75%            1.800000  \n",
       "max            2.500000  "
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal length (cm)    10\n",
       "sepal width (cm)     10\n",
       "petal length (cm)    10\n",
       "petal width (cm)     10\n",
       "dtype: int64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>1.500000e+02</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.468455e-15</td>\n",
       "      <td>-1.823726e-15</td>\n",
       "      <td>-9.473903e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.003350e+00</td>\n",
       "      <td>1.003350e+00</td>\n",
       "      <td>1.003350e+00</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.870024e+00</td>\n",
       "      <td>-2.433947e+00</td>\n",
       "      <td>-1.447076e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-9.006812e-01</td>\n",
       "      <td>-5.923730e-01</td>\n",
       "      <td>-1.183812e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-5.250608e-02</td>\n",
       "      <td>-1.319795e-01</td>\n",
       "      <td>1.325097e-01</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.745011e-01</td>\n",
       "      <td>5.586108e-01</td>\n",
       "      <td>7.906707e-01</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.492019e+00</td>\n",
       "      <td>3.090775e+00</td>\n",
       "      <td>1.712096e+00</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal width (cm)      target\n",
       "count       1.500000e+02      1.500000e+02      1.500000e+02  150.000000\n",
       "mean       -1.468455e-15     -1.823726e-15     -9.473903e-16    1.000000\n",
       "std         1.003350e+00      1.003350e+00      1.003350e+00    0.819232\n",
       "min        -1.870024e+00     -2.433947e+00     -1.447076e+00    0.000000\n",
       "25%        -9.006812e-01     -5.923730e-01     -1.183812e+00    0.000000\n",
       "50%        -5.250608e-02     -1.319795e-01      1.325097e-01    1.000000\n",
       "75%         6.745011e-01      5.586108e-01      7.906707e-01    2.000000\n",
       "max         2.492019e+00      3.090775e+00      1.712096e+00    2.000000"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(X.corr())\n",
    "data_ = pd.DataFrame(X_scaled, columns=iris.feature_names)\n",
    "data_['target'] = y\n",
    "data_\n",
    "\n",
    "sns.heatmap(data_.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sepal length (cm)</td>\n",
       "      <td>3.417679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sepal width (cm)</td>\n",
       "      <td>1.311843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>petal width (cm)</td>\n",
       "      <td>4.374958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>target</td>\n",
       "      <td>1.584916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Features       VIF\n",
       "0  sepal length (cm)  3.417679\n",
       "1   sepal width (cm)  1.311843\n",
       "2   petal width (cm)  4.374958\n",
       "3             target  1.584916"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vif_data = pd.DataFrame()\n",
    "vif_data['Features'] = data_.columns\n",
    "vif_data['VIF'] = [variance_inflation_factor(data_.values,i) for i in range(len(data_.columns))]\n",
    "vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.019004</td>\n",
       "      <td>-1.315444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.143017</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>-1.315444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.385353</td>\n",
       "      <td>0.328414</td>\n",
       "      <td>-1.315444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.506521</td>\n",
       "      <td>0.098217</td>\n",
       "      <td>-1.315444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.021849</td>\n",
       "      <td>1.249201</td>\n",
       "      <td>-1.315444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.038005</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>1.448832</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.553333</td>\n",
       "      <td>-1.282963</td>\n",
       "      <td>0.922303</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.795669</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>1.053935</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.432165</td>\n",
       "      <td>0.788808</td>\n",
       "      <td>1.448832</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.068662</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.790671</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal width (cm)  target\n",
       "0            -0.900681          1.019004         -1.315444       0\n",
       "1            -1.143017         -0.131979         -1.315444       0\n",
       "2            -1.385353          0.328414         -1.315444       0\n",
       "3            -1.506521          0.098217         -1.315444       0\n",
       "4            -1.021849          1.249201         -1.315444       0\n",
       "..                 ...               ...               ...     ...\n",
       "145           1.038005         -0.131979          1.448832       2\n",
       "146           0.553333         -1.282963          0.922303       2\n",
       "147           0.795669         -0.131979          1.053935       2\n",
       "148           0.432165          0.788808          1.448832       2\n",
       "149           0.068662         -0.131979          0.790671       2\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_= data_[vif_data[vif_data.VIF <= 20].Features.values]\n",
    "data_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_.drop(columns='target'), data_.target, test_size=0.2, random_state=123, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters: {'learning_rate': 0.003, 'max_depth': 3, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.003, 0.01, 0.1, 0.2],\n",
    "    # 'subsample': [0.7, 0.8, 0.9],\n",
    "    # 'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    # 'class_weight': ['balanced'],\n",
    "    # 'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Set up StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softprob', num_class=3, use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=kfold, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric='rmse', feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.003, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=100, n_jobs=None, num_class=3,\n",
      "              num_parallel_tree=None, ...)\n"
     ]
    }
   ],
   "source": [
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.97\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "print(f'F1 score: {f1:.2f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>-0.416010</td>\n",
       "      <td>-1.513160</td>\n",
       "      <td>-0.130755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>-1.264185</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>-1.183812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>1.038005</td>\n",
       "      <td>0.558611</td>\n",
       "      <td>1.712096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.795669</td>\n",
       "      <td>0.328414</td>\n",
       "      <td>1.053935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-1.748856</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.385353</td>\n",
       "      <td>0.328414</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>2.249683</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>1.448832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.553333</td>\n",
       "      <td>-1.282963</td>\n",
       "      <td>0.395774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.189830</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.790671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-1.143017</td>\n",
       "      <td>0.098217</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.709595</td>\n",
       "      <td>-1.183812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1.038005</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.659038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.052506</td>\n",
       "      <td>-0.822570</td>\n",
       "      <td>0.922303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.310998</td>\n",
       "      <td>-0.362176</td>\n",
       "      <td>0.264142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>2.249683</td>\n",
       "      <td>1.709595</td>\n",
       "      <td>1.317199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1.159173</td>\n",
       "      <td>-0.592373</td>\n",
       "      <td>0.264142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>-1.748856</td>\n",
       "      <td>0.328414</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-1.506521</td>\n",
       "      <td>1.249201</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.779513</td>\n",
       "      <td>0.788808</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.416010</td>\n",
       "      <td>2.630382</td>\n",
       "      <td>-1.315444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.019004</td>\n",
       "      <td>-1.183812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.795669</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.790671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.310998</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>0.790671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.553333</td>\n",
       "      <td>0.558611</td>\n",
       "      <td>0.527406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2.128516</td>\n",
       "      <td>-0.131979</td>\n",
       "      <td>1.185567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.553333</td>\n",
       "      <td>-1.282963</td>\n",
       "      <td>0.922303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>-1.021849</td>\n",
       "      <td>-1.743357</td>\n",
       "      <td>-0.262387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1.038005</td>\n",
       "      <td>0.098217</td>\n",
       "      <td>0.395774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.432165</td>\n",
       "      <td>-1.973554</td>\n",
       "      <td>0.395774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.038005</td>\n",
       "      <td>0.098217</td>\n",
       "      <td>0.264142</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal width (cm)\n",
       "80           -0.416010         -1.513160         -0.130755\n",
       "45           -1.264185         -0.131979         -1.183812\n",
       "144           1.038005          0.558611          1.712096\n",
       "110           0.795669          0.328414          1.053935\n",
       "38           -1.748856         -0.131979         -1.315444\n",
       "2            -1.385353          0.328414         -1.315444\n",
       "135           2.249683         -0.131979          1.448832\n",
       "72            0.553333         -1.282963          0.395774\n",
       "138           0.189830         -0.131979          0.790671\n",
       "34           -1.143017          0.098217         -1.315444\n",
       "19           -0.900681          1.709595         -1.183812\n",
       "77            1.038005         -0.131979          0.659038\n",
       "101          -0.052506         -0.822570          0.922303\n",
       "63            0.310998         -0.362176          0.264142\n",
       "117           2.249683          1.709595          1.317199\n",
       "76            1.159173         -0.592373          0.264142\n",
       "42           -1.748856          0.328414         -1.315444\n",
       "22           -1.506521          1.249201         -1.315444\n",
       "28           -0.779513          0.788808         -1.315444\n",
       "33           -0.416010          2.630382         -1.315444\n",
       "17           -0.900681          1.019004         -1.183812\n",
       "116           0.795669         -0.131979          0.790671\n",
       "127           0.310998         -0.131979          0.790671\n",
       "56            0.553333          0.558611          0.527406\n",
       "105           2.128516         -0.131979          1.185567\n",
       "146           0.553333         -1.282963          0.922303\n",
       "93           -1.021849         -1.743357         -0.262387\n",
       "86            1.038005          0.098217          0.395774\n",
       "68            0.432165         -1.973554          0.395774\n",
       "65            1.038005          0.098217          0.264142"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning Model Implementation Steps:\n",
    "1. Missing Values Handling:\n",
    "    - Use MICE technique for data imputation\n",
    "    - Use SimpleImputer from sklearn: mean, median, most_frequent, constant\n",
    "2. Correlated Feature Handling:\n",
    "    - Variance Inflation Factor\n",
    "    - If high correlation then drop the features Iteratively\n",
    "3. One-Hot Encoder: pd.getdummies\n",
    "4. Feature Scaling:\n",
    "    - Check for Normal Distribution using Shapiro-Wilk Test\n",
    "    - MinMax scaler, Standard Scaler, RobustScaler for Normalization\n",
    "    - RobutScaler if Outlier and data not normal, Standard Scaler if normal\n",
    "5. StratefiedKfold: Cross-validation\n",
    "6. GridSearchCV:\n",
    "    - Best Combination of Parameters\n",
    "7. Model Evaluation:\n",
    "    - accuracy\n",
    "    - f1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Classification:\n",
    "XGBoost (or Randomforest)\n",
    "SVM\n",
    "KNearestClassifier\n",
    "\n",
    "Regression:\n",
    "- OLS Regression (Maximum Likelihood Estimator: MLE)\n",
    "- Ridge\n",
    "- XGBRegressor (RFRegressor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Introduce some missing values for demonstration\n",
    "np.random.seed(0)\n",
    "missing_mask = np.random.rand(*X.shape) < 0.1\n",
    "X[missing_mask] = np.nan\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('imputer', IterativeImputer(random_state=42)),  # Data imputation step\n",
    "    ('feature_selection', SelectKBest(f_classif)),  # Feature selection step\n",
    "    ('scaler', StandardScaler()),  # Feature scaling step\n",
    "    ('mlp', MLPClassifier(random_state=42))  # MLPClassifier step\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'feature_selection__k': [2, 3, 4],  # Number of features to select\n",
    "    'mlp__hidden_layer_sizes': [(50, 50, 50), (50, 100, 50), (100,)],  # Different architectures\n",
    "    'mlp__activation': ['tanh', 'relu'],  # Activation functions\n",
    "    'mlp__solver': ['sgd', 'adam'],  # Solvers\n",
    "    'mlp__alpha': [0.0001, 0.05],  # Regularization parameter\n",
    "    'mlp__learning_rate': ['constant', 'adaptive'],  # Learning rate schedules\n",
    "    'mlp__max_iter': [200, 400, 600]  # Number of epochs\n",
    "}\n",
    "\n",
    "# Set up StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=kfold, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Best model\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm): Statistic=0.9761, p-value=0.0102, Normal (p>0.05)=False\n",
      "sepal width (cm): Statistic=0.9849, p-value=0.1011, Normal (p>0.05)=True\n",
      "petal length (cm): Statistic=0.8763, p-value=0.0000, Normal (p>0.05)=False\n",
      "petal width (cm): Statistic=0.9018, p-value=0.0000, Normal (p>0.05)=False\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import shapiro\n",
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "\n",
    "# Perform Shapiro-Wilk test for each feature\n",
    "shapiro_results = {}\n",
    "for feature in df.columns:\n",
    "    stat, p_value = shapiro(df[feature])\n",
    "    shapiro_results[feature] = {'Statistic': stat, 'p-value': p_value, 'Normal (p>0.05)': p_value > 0.05}\n",
    "\n",
    "# Print the results\n",
    "for feature, result in shapiro_results.items():\n",
    "    print(f\"{feature}: Statistic={result['Statistic']:.4f}, p-value={result['p-value']:.4f}, Normal (p>0.05)={result['Normal (p>0.05)']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I have a class defined in python, which has two functions: one for building XGBClassifier and another with MLPClassifier\n",
    "\n",
    "MLPClassfier functions contains the below:\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'feature_selection__k': [2, 3, 4],  # Number of features to select\n",
    "    'mlp__hidden_layer_sizes': [(50, 50, 50), (50, 100, 50), (100,)],  # Different architectures\n",
    "    'mlp__activation': ['tanh', 'relu'],  # Activation functions\n",
    "    'mlp__solver': ['sgd', 'adam'],  # Solvers\n",
    "    'mlp__alpha': [0.0001, 0.05],  # Regularization parameter\n",
    "    'mlp__learning_rate': ['constant', 'adaptive'],  # Learning rate schedules\n",
    "    'mlp__max_iter': [200, 400, 600]  # Number of epochs\n",
    "}\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "XGBClassfier contains this:\n",
    "# Define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.003, 0.01, 0.1, 0.2],\n",
    "    # 'subsample': [0.7, 0.8, 0.9],\n",
    "    # 'colsample_bytree': [0.7, 0.8, 0.9],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    # 'class_weight': ['balanced'],\n",
    "    # 'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Initialize the XGBClassifier\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softprob', num_class=3, use_label_encoder=False, eval_metric='mlogloss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 648 candidates, totalling 3240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/aakashrathod/opt/anaconda3/envs/pyenv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "1080 fits failed out of a total of 3240.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "644 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aakashrathod/opt/anaconda3/envs/pyenv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/aakashrathod/opt/anaconda3/envs/pyenv/lib/python3.8/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/aakashrathod/opt/anaconda3/envs/pyenv/lib/python3.8/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/aakashrathod/opt/anaconda3/envs/pyenv/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "436 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/aakashrathod/opt/anaconda3/envs/pyenv/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/aakashrathod/opt/anaconda3/envs/pyenv/lib/python3.8/site-packages/sklearn/base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"/Users/aakashrathod/opt/anaconda3/envs/pyenv/lib/python3.8/site-packages/sklearn/base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"/Users/aakashrathod/opt/anaconda3/envs/pyenv/lib/python3.8/site-packages/sklearn/utils/_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/aakashrathod/opt/anaconda3/envs/pyenv/lib/python3.8/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [       nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.94666667 0.96       0.96\n",
      " 0.96666667 0.96       0.96       0.96666667 0.96666667 0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.94666667 0.96       0.96       0.96666667 0.96       0.96\n",
      " 0.96666667 0.96666667 0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96              nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94666667 0.96       0.96       0.96666667 0.96       0.96\n",
      " 0.96666667 0.96666667 0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.94666667 0.96       0.96\n",
      " 0.96666667 0.96       0.96       0.96666667 0.96666667 0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.94666667 0.96       0.96\n",
      " 0.96666667 0.96       0.96       0.96666667 0.96666667 0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.94666667 0.96       0.96       0.96666667 0.96       0.96\n",
      " 0.96666667 0.96666667 0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96              nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.94666667 0.96       0.96       0.96666667 0.96       0.96\n",
      " 0.96666667 0.96666667 0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.94666667 0.96       0.96\n",
      " 0.96666667 0.96       0.96       0.96666667 0.96666667 0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      " 0.96       0.96       0.96       0.96       0.96       0.96\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95333333 0.94666667 0.94666667\n",
      " 0.94666667 0.94666667 0.95333333 0.96       0.96       0.96\n",
      " 0.94666667 0.94666667 0.94666667 0.94666667 0.94666667 0.94666667\n",
      " 0.96       0.96       0.96       0.96       0.95333333 0.96\n",
      " 0.96       0.95333333 0.96       0.96       0.96       0.96\n",
      " 0.95333333 0.94666667 0.94666667 0.94666667 0.94666667 0.95333333\n",
      " 0.96       0.96       0.96       0.94666667 0.94666667 0.94666667\n",
      " 0.94666667 0.94666667 0.94666667 0.96       0.96       0.96\n",
      " 0.96       0.95333333 0.96       0.96       0.95333333 0.96\n",
      " 0.96       0.96       0.96              nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95333333 0.94666667 0.94666667 0.94666667 0.94666667 0.95333333\n",
      " 0.96       0.96       0.96       0.94666667 0.94666667 0.94666667\n",
      " 0.94666667 0.94666667 0.94666667 0.96       0.96       0.96\n",
      " 0.96       0.95333333 0.96       0.96       0.95333333 0.96\n",
      " 0.96       0.96       0.96       0.95333333 0.94666667 0.94666667\n",
      " 0.94666667 0.94666667 0.95333333 0.96       0.96       0.96\n",
      " 0.94666667 0.94666667 0.94666667 0.94666667 0.94666667 0.94666667\n",
      " 0.96       0.96       0.96       0.96       0.95333333 0.96\n",
      " 0.96       0.95333333 0.96       0.96       0.96       0.96\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan 0.95333333 0.94666667 0.94666667\n",
      " 0.94666667 0.94666667 0.95333333 0.96       0.96       0.96\n",
      " 0.94666667 0.94666667 0.94666667 0.94666667 0.94666667 0.94666667\n",
      " 0.96       0.96       0.96       0.96       0.95333333 0.96\n",
      " 0.96       0.95333333 0.96       0.96       0.96       0.96\n",
      " 0.95333333 0.94666667 0.94666667 0.94666667 0.94666667 0.95333333\n",
      " 0.96       0.96       0.96       0.94666667 0.94666667 0.94666667\n",
      " 0.94666667 0.94666667 0.94666667 0.96       0.96       0.96\n",
      " 0.96       0.95333333 0.96       0.96       0.95333333 0.96\n",
      " 0.96       0.96       0.96              nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.95333333 0.94666667 0.94666667 0.94666667 0.94666667 0.95333333\n",
      " 0.96       0.96       0.96       0.94666667 0.94666667 0.94666667\n",
      " 0.94666667 0.94666667 0.94666667 0.96       0.96       0.96\n",
      " 0.96       0.95333333 0.96       0.96       0.95333333 0.96\n",
      " 0.96       0.96       0.96       0.95333333 0.94666667 0.94666667\n",
      " 0.94666667 0.94666667 0.95333333 0.96       0.96       0.96\n",
      " 0.94666667 0.94666667 0.94666667 0.94666667 0.94666667 0.94666667\n",
      " 0.96       0.96       0.96       0.96       0.95333333 0.96\n",
      " 0.96       0.95333333 0.96       0.96       0.96       0.96      ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'bootstrap': True, 'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Cross-validation accuracy: 0.97 +/- 0.03\n",
      "Accuracy on test set: 0.97\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      0.90      0.95        10\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.97        30\n",
      "   macro avg       0.97      0.97      0.97        30\n",
      "weighted avg       0.97      0.97      0.97        30\n",
      "\n",
      "Confusion Matrix:\n",
      "[[10  0  0]\n",
      " [ 0  9  1]\n",
      " [ 0  0 10]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Load the dataset (using Iris dataset as an example)\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20, 30],   # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10],   # Minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': [1, 2, 4],     # Minimum number of samples required to be at a leaf node\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider at each split\n",
    "    'bootstrap': [True, False]         # Whether bootstrap samples are used when building trees\n",
    "}\n",
    "\n",
    "# Set up Stratified K-Fold cross-validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=kfold, scoring='accuracy', verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit the model\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Best parameters found\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "\n",
    "# Best model\n",
    "best_rf_model = grid_search.best_estimator_\n",
    "\n",
    "# Perform cross-validation with best model (optional)\n",
    "cv_results = cross_val_score(best_rf_model, X, y, cv=kfold, scoring='accuracy')\n",
    "print(f\"Cross-validation accuracy: {np.mean(cv_results):.2f} +/- {np.std(cv_results):.2f}\")\n",
    "\n",
    "# Alternatively, split data into train and test sets and evaluate the best model\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Fit and predict with best model\n",
    "best_rf_model.fit(X_train, y_train)\n",
    "y_pred = best_rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy on test set: {accuracy:.2f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3391337ea60e7587f281161a970fce2a1299e7f61db837e2842263805a76e468"
  },
  "kernelspec": {
   "display_name": "Python 3.8.18 ('pyenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
